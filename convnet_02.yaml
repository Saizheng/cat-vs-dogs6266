!obj:pylearn2.train.Train {
    dataset: &train !obj:ift6266h15.code.pylearn2.datasets.variable_image_dataset.DogsVsCats {
        transformer: &transformer !obj:ift6266h15.code.pylearn2.datasets.variable_image_dataset.RandomCrop {
            scaled_size: 260,
            crop_size: 256,
        },
        start: 0,
        stop: 20000,
    },
    model: !obj:pylearn2.models.mlp.MLP {
        input_space: !obj:pylearn2.space.Conv2DSpace {
            shape: [256, 256],
            num_channels: 3,
            },
        layers: [!obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: "h0",
                     output_channels: 32,
                     irange: 0.05,
                     kernel_shape: [3, 3],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2]
                 },
                 !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: "h1",
                     output_channels: 32,
                     irange: 0.05,
                     kernel_shape: [3, 3],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2]
                 },
                 !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: "h2",
                     output_channels: 64,
                     irange: 0.05,
                     kernel_shape: [5, 5],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2]
                 },
                 !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: "h3",
                     output_channels: 128,
                     irange: 0.05,
                     kernel_shape: [5, 5],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2]
                 },
                 !obj:pylearn2.models.mlp.RectifiedLinear {
                     layer_name: "h4",
                     dim: 256,
                     irange: 0.1
                 },
                 !obj:pylearn2.models.mlp.RectifiedLinear {
                     layer_name: "h5",
                     dim: 324,
                     irange: 0.1
                 },
                 !obj:pylearn2.models.mlp.RectifiedLinear {
                     layer_name: "h6",
                     dim: 128,
                     irange: 0.1
                 },
                 !obj:pylearn2.models.mlp.Softmax {
                     layer_name: "y",
                     n_classes: 2,
                     istdev: 0.1
                 },
                ],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 50,
        train_iteration_mode: "batchwise_shuffled_sequential",
        monitoring_batch_size: 10,
        monitoring_batches: 10,
        monitor_iteration_mode: "batchwise_shuffled_sequential",
        learning_rate: 0.001,
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: 0.9
        },
        monitoring_dataset:
            {
                'train': *train,
                'valid': !obj:ift6266h15.code.pylearn2.datasets.variable_image_dataset.DogsVsCats {
                    transformer: *transformer,
                    start: 20000,
                    stop: 22500,
                },
                'test': !obj:ift6266h15.code.pylearn2.datasets.variable_image_dataset.DogsVsCats {
                    transformer: *transformer,
                    start: 22500,
                    stop: 25000,
            },
        },
        cost: !obj:pylearn2.costs.cost.MethodCost {
            method: 'cost_from_X',
        },
        termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter {
            max_epochs: 100
        },
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: "valid_y_misclass",
             save_path: "convnet05_best.pkl"
             },
    ],
    save_path: "convnet05.pkl",
    save_freq: 1
}

